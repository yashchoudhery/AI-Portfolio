---
title: AI Portfolio Backend
emoji: ğŸ¤–
colorFrom: blue
colorTo: purple
sdk: docker
app_port: 7860
---


# AI Portfolio Chatbot with RAG

A resumeâ€‘focused, firstâ€‘person Q&A chatbot that uses Retrievalâ€‘Augmented Generation (RAG) to deliver accurate, grounded answers about skills, experience, education, and projects. Built with LangChain, FAISS, Sentence Transformers, FastAPI, Streamlit, and Groq for lowâ€‘latency inference.

## Overview

This app ingests a resume (PDF/DOCX/TXT), chunks and embeds it locally, stores vectors in FAISS, retrieves relevant context for each query, and generates concise firstâ€‘person answersâ€”ideal for recruiter interactions.

## Features

- Retrievalâ€‘Augmented Generation for grounded, lowâ€‘hallucination answers.
- Local embeddings via Sentence Transformers (allâ€‘MiniLMâ€‘L6â€‘v2) for fast semantic search on CPU/GPU.
- FAISS vector database for highâ€‘performance similarity search and local persistence.
- Multiâ€‘format loaders (PDF/DOCX/TXT) + resumeâ€‘tuned chunking.
- FastAPI backend (typed models, /chat, /health, /info) and Streamlit UI (dark/light themes, quick actions).
- Groq chat inference for ultraâ€‘low latency with Llama and Mixtral.

## Architecture

User â†’ Streamlit UI â†’ FastAPI Backend â†’ LangChain RAG
â†“
FAISS Vector DB
â†“
Groq/OpenAI Chat LLM
â†“
Firstâ€‘person response


Indexing (load â†’ split â†’ embed â†’ store) happens once; serving (embed â†’ retrieve â†’ generate) runs per query.

## Tech Stack

| Layer          | Choice                                     | Why |
|----------------|---------------------------------------------|-----|
| Orchestration  | LangChain                                   | Chains, retrievers, loaders, prompts for RAG |
| Embeddings     | Sentence Transformers (allâ€‘MiniLMâ€‘L6â€‘v2)    | Fast, 384â€‘dim embeddings, excellent CPU perf |
| Vector DB      | FAISS                                       | Efficient similarity search, local persistence |
| Loaders        | PyPDFLoader, Docx2txtLoader                 | Reliable PDF/DOCX parsing |
| Backend        | FastAPI                                     | Highâ€‘performance Python API, OpenAPI |
| Frontend       | Streamlit                                   | Rapid, modern UI with simple deployment |
| LLM Inference  | Groq Python SDK                             | Lowâ€‘latency Llama/Mixtral chat completions |

## Installation

Create a virtual environment and install dependencies:

python -m venv .venv

macOS/Linux
source .venv/bin/activate

Windows
..venv\Scripts\activate

pip install -r requirements.txt


## Configuration

Provide API keys and set resume path:

.env
GROQ_API_KEY=your_groq_key
OPENAI_API_KEY=your_openai_key # optional
TAVILY_API_KEY=your_tavily_key # optional




In `ai_agent.py`, set the resume file path to one of:
- `./resume.pdf` (textâ€‘based PDF recommended)
- `./resume.docx`
- `./resume.txt` (most robust if parsing issues occur)

## Running

Start backend and frontend:

Terminal 1
python Backend.py

Terminal 2
streamlit run frontend.py


- Backend: FastAPI on http://127.0.0.1:9999 (endpoints: `/chat`, `/health`, `/info`)
- Frontend: Streamlit on http://localhost:8501

## Usage

Ask resumeâ€‘related questions such as:
- â€œWhat programming languages do you know?â€
- â€œTell me about your work experience.â€
- â€œWhat projects have you worked on?â€
- â€œWhatâ€™s your educational background?â€

Nonâ€‘resume queries are politely redirected to keep the conversation professional and on-topic.

## API (FastAPI)

- Base URL: `http://127.0.0.1:9999`

Example request:
curl -X POST "http://127.0.0.1:9999/chat"
-H "Content-Type: application/json"
-d '{
"model_name": "llama-3.3-70b-versatile",
"model_provider": "Groq",
"prompt": "Act as AI Assistant",
"messages": ["What programming languages do you know?"],
"allow_search": false
}'


Example response:
{
"response": "I'm proficient in Python, Java, and JavaScript...",
"is_resume_related": true
}


## Tuning

- Retrieval: adjust `search_kwargs={"k": 3..5}` for breadth vs. precision.
- Chunking: tune `chunk_size` and `chunk_overlap` for your resume format.
- Models: switch between Llama 3.3 70B and Mixtral 8x7B via Groq for latency/quality tradeoffs.

## Troubleshooting

- Poor PDF parsing? Try DOCX or export to TXT and reâ€‘index.
- Vector store reload issues? Ensure compatible FAISS versions and safe deserialization logic.
- Frontend connection errors? Confirm backend is running and port/URL match.
- Embedding download failures? Check Sentence Transformers version and network access.

## Performance

- First run: downloads allâ€‘MiniLMâ€‘L6â€‘v2 (~90 MB) and builds FAISS index.
- Subsequent runs: fast (2â€“3 s typical), thanks to cached models and persisted vectors.

## Project Structure

.
â”œâ”€â”€ ai_agent.py # RAG pipeline & AI agent
â”œâ”€â”€ Backend.py # FastAPI server (/chat, /health, /info)
â”œâ”€â”€ frontend.py # Streamlit UI
â”œâ”€â”€ requirements.txt # Dependencies
â”œâ”€â”€ .env # API keys (not committed)
â”œâ”€â”€ .gitignore # Protects secrets, resume files, vectors, etc.
â””â”€â”€ faiss_resume_vectorstore/ # Local vector DB (not committed)




## Sources

- LangChain RAG Tutorial: https://python.langchain.com/docs/tutorials/rag/  
- LangChain Vector Stores: https://python.langchain.com/docs/integrations/vectorstores/  
- FAISS (LangChain Integration): https://python.langchain.com/docs/integrations/vectorstores/faiss/  
- FAISS Docs: https://faiss.ai/index.html  
- FAISS GitHub: https://github.com/facebookresearch/faiss  
- Sentence Transformers (allâ€‘MiniLMâ€‘L6â€‘v2): https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2  
- PyPDFLoader: https://python.langchain.com/docs/integrations/document_loaders/pypdfloader/  
- Docx2txtLoader: https://python.langchain.com/api_reference/community/document_loaders/langchain_community.document_loaders.word_document.Docx2txtLoader.html  
- FastAPI: https://fastapi.tiangolo.com  
- Streamlit: https://docs.streamlit.io  
- Groq Python SDK: https://github.com/groq/groq-python




pip install langgraph
pip install langchain_groq langchain_openai langchain_community
pip install -U langchain-tavily langchain
pip install -U langchain-tavily
pip install -U langchain
pip install pydantic
pip install fastapi
pip install uvicorn
pip install streamlit